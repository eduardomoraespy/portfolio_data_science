{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_forest.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFL01YBSpb58pF5Ov51TXU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVFLWS_jPunh"
      },
      "source": [
        "<h1>\n",
        "Introdução\n",
        "</h1>\n",
        "<p>\n",
        "\n",
        "As <b>árvores de decisão</b> deixam você com uma decisão difícil. Uma árvore profunda com muitas folhas se ajustará demais porque cada previsão vem de dados históricos de apenas algumas casas em sua folha. Mas uma árvore rasa com poucas folhas terá um desempenho ruim porque não consegue capturar tantas distinções nos dados brutos.\n",
        "\n",
        "Mesmo as técnicas de modelagem mais sofisticadas de hoje enfrentam essa tensão entre <b>underfitting e overfitting.</b> Porém, muitos modelos têm ideias inteligentes que podem levar a um melhor desempenho. Veremos a <b>random forest</b> como exemplo.\n",
        "\n",
        "A <b>random forest</b> usa muitas árvores e faz uma previsão calculando a <b>média das previsões de cada árvore componente.</b> Geralmente, tem uma precisão preditiva muito melhor do que uma única árvore de decisão e funciona bem com os parâmetros padrão. Se você continuar modelando, poderá aprender mais modelos com desempenho ainda melhor, mas muitos deles são sensíveis à obtenção dos parâmetros corretos.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFeacvSCRGzR"
      },
      "source": [
        "<h2>Exemplo </h2>\n",
        "<p>\n",
        "Você já viu o código para carregar os dados algumas vezes. No final do carregamento de dados, temos as seguintes variáveis:\n",
        "\n",
        "<ul>\n",
        "\n",
        "<li> train_X</li>\n",
        "<li>val_X </li>\n",
        "<li>train_y </li>\n",
        "<li>val_y </li>\n",
        "</ul>\n",
        "\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPtx7EO1PYyl"
      },
      "source": [
        "#Carregar base de dados\n",
        "import pandas as pd\n",
        "\n",
        "data_house = pd.read_csv('melb_data.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u47On_mBTCDM"
      },
      "source": [
        "# Filtrando as linhas com valores ausentes\n",
        "data_house = data_house.dropna(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhpv6LlkTgjG"
      },
      "source": [
        "# Escolendo alvo e recursos\n",
        "\n",
        "#Alvo\n",
        "y = data_house.Price # Alvo é a coluna preço\n",
        "\n",
        "# Recursos\n",
        "house_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea','YearBuilt', 'Lattitude', 'Longtitude']\n",
        "\n",
        "# O declarando objeto X para receber a lista de recursos\n",
        "X = data_house[house_features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eNlReJ-UohW"
      },
      "source": [
        "# Criando o modelo de machine learning\n",
        "from sklearn.model_selection import train_test_split # função para treino e teste\n",
        "\n",
        "#dividir os dados em dados de treinamento e validação, para recursos e destino\n",
        "# A divisão é baseada em um gerador de números aleatórios. Fornecendo um valor numérico para\n",
        "# o argumento random_state garante que obteremos a mesma divisão toda vez que\n",
        "# execute este script.\n",
        "\n",
        "# Dividir os dados em dados de treinamento e validação, para recursos e destino.\n",
        "# A divisão é baseada em um gerador de números aleatórios. Fornecendo um valor númerico para o argumentos random_state\n",
        "# garante que obteremos a mesma divisão toda vez que execute este script\n",
        "\n",
        "# Dividindo em trainamento e validação\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X, y, random_state=0) # os objetos vão receber a função que tem como parâmetro\n",
        "# O alvo que é y e os recuros que é x e ainda o random_state para padronizar as saidas dos números aleatórios que são gerados, com a finalidade\n",
        "# de que cada execução esses valores não mude."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_Ck5Pa3ZufD"
      },
      "source": [
        "<p>\n",
        "Construímos um modelo de <b>Random Forest</b> de forma semelhante a como construímos uma árvore de decisão no scikit-learn - desta vez usando a classe <b>RandomForestRegressor</b> em vez de DecisionTreeRegressor.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqGTGTDVaAo7",
        "outputId": "85d9e6e7-74e7-4279-bbee-6cc4c2c1c770"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Modelo\n",
        "forest_model = RandomForestRegressor(random_state=1)\n",
        "forest_model.fit(train_X, train_y)\n",
        "\n",
        "house_pred = forest_model.predict(valid_X)\n",
        "\n",
        "print(mean_absolute_error(valid_y, house_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "191669.7536453626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FteTlWmcWca"
      },
      "source": [
        "<h2>Conclusão </h2>\n",
        "<p>\n",
        "Provavelmente há espaço para melhorias adicionais, mas esta é uma grande melhoria em relação ao erro da melhor árvore de decisão de 250.000. Existem parâmetros que permitem alterar o desempenho do Random Forest da mesma forma que alteramos a profundidade máxima da árvore de decisão única. Mas uma das melhores características dos modelos Random Forest é que eles geralmente funcionam razoavelmente, mesmo sem esse ajuste.\n",
        "</p>"
      ]
    }
  ]
}